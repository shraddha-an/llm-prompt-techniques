{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP1GboVXgdGsL6imnvKzabW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shraddha-an/llm-prompt-techniques/blob/main/LLM_Prompting_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **0. Installations**"
      ],
      "metadata": {
        "id": "RFP6-VBdBigE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaRKjvUn9tVE"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install -U transformers==4.36.1 accelerate bitsandbytes --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "2xUyNvRamBwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Load Model + Tokenizer**"
      ],
      "metadata": {
        "id": "lC-RlWK3Btcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **i. Model + Tokenizer**"
      ],
      "metadata": {
        "id": "ZOCDuKoPCZo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import torch\n",
        "\n",
        "model_name = \"databricks/dolly-v2-7b\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             load_in_8bit = False,\n",
        "                                             torch_dtype = torch.bfloat16,\n",
        "                                             device_map = \"auto\",\n",
        "                                             trust_remote_code = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9NCcYRsCR5A",
        "outputId": "b9c07a66-6f03-4434-e926-d4f8184a8662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **iii. Pipeline**"
      ],
      "metadata": {
        "id": "QTO1iwfxDT31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-generation\",\n",
        "                model = model,\n",
        "                tokenizer = tokenizer,\n",
        "                device_map = \"auto\",\n",
        "                torch_dtype = torch.bfloat16)"
      ],
      "metadata": {
        "id": "uSAO1TzrDVYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Inference**"
      ],
      "metadata": {
        "id": "2g1WBgeCEXpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(prompt: str, pipe: pipeline = pipe) -> str:\n",
        "  \"\"\"\n",
        "  Prompt the text-generation pipeline to generate a response.\n",
        "\n",
        "  Args:\n",
        "    prompt (str): prompt\n",
        "    pipe (pipeline): Transformers text-generation pipeline consisting of the LLM.\n",
        "\n",
        "  Return:\n",
        "    answer (str): LLM response to the prompt\n",
        "  \"\"\"\n",
        "  sequences = pipe(prompt,\n",
        "                  do_sample = True,\n",
        "                  return_full_text = False,\n",
        "                  temperature = 0.2,\n",
        "                  num_return_sequences = 1)\n",
        "\n",
        "  answer = sequences[0]['generated_text']\n",
        "\n",
        "  return answer"
      ],
      "metadata": {
        "id": "o8JlQSMQEZJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Zero-shot prompting**\n",
        "Simple prompt asking the LLM to perform a task.\n"
      ],
      "metadata": {
        "id": "tcPuHgLfOHCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zs_prompt = \"\"\"Identify whether the text is Negative or Positive.\n",
        "\n",
        "Text: I visited a new restaurant last week and it'll be my first and last time eating there. I would not even rate it a 1 star, the food and hygiene was awful, and the staff behaved extremely rude to us.\"\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "zs_answer = generate_answer(zs_prompt)\n",
        "print(zs_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xg1fPTwMe4e",
        "outputId": "4130cfb8-ce88-4b29-da01-1d1d6d7ced00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zs_prompt2 = \"\"\"Identify whether the text is Negative or Positive.\n",
        "\n",
        "Text: I visited a new restaurant last week and the food was delicious! The ambience was pleasant and the chef even greeted us halfway through our meal!\"\n",
        "\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "generate_answer(zs_prompt2)"
      ],
      "metadata": {
        "id": "y0SoW3SDPTBl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b0d2070e-d4fd-4b6e-a2c9-e79f04938aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Few-shot prompting**"
      ],
      "metadata": {
        "id": "jPXs25H2kexZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prompt Format for Dolly**\n",
        "---\n",
        "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "\\### Instruction:\n",
        "\n",
        "Describe the task in detail, as well as the \"role\" the LLM is supposed to adopt. Be sure to explicitly tell the LLM what *not* to do in the instructions.\n",
        "\n",
        "\n",
        "*I added this bit ⬇️ to create a few-shot prompt*\n",
        "\n",
        "\\### EXAMPLES\n",
        "1. Example 1.\n",
        "\n",
        "  Output = <response_to_the_task>\n",
        "\n",
        "2. Example 2.\n",
        "\n",
        "  Output = <response_to_the_task>\n",
        "\n",
        "3. Test sentence.\n",
        "\n",
        "\\### Response:\n",
        "\n",
        "Output =\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\\### End\n"
      ],
      "metadata": {
        "id": "omnmd8SmvEc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some test sentences\n",
        "t1 = \"That was an awesome class and an even cooler teacher. I liked how she was patient and was good at explaining things. Definitely will take the class again.\"\n",
        "t2 = \"Hmm this was terrible. What a waste of my time!\""
      ],
      "metadata": {
        "id": "PL6K8ehGyWwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "INSTRUCTION_KEY = \"### Instruction:\"\n",
        "INPUT_KEY = \"Input:\"\n",
        "RESPONSE_KEY = f\"### Response:\\nSentiment = \"\n",
        "END_KEY = \"### End\""
      ],
      "metadata": {
        "id": "pBjXkHWf-itX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **a. Positive**"
      ],
      "metadata": {
        "id": "ljPGr5uiLPRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = t1\n",
        "\n",
        "example_string = f\"\"\"\n",
        "You will be given a few example sentences with their correct sentiment. Learn to identify the sentiment of the text and predict whether it is Negative, Positive or Neutral.\n",
        "Only respond with the sentiment label.\n",
        "\n",
        "### EXAMPLES\n",
        "1. This is awesome!\n",
        "Sentiment = Positive\n",
        "\n",
        "2. This is bad!\n",
        "Sentiment = Negative\n",
        "\n",
        "3. Well not much to speak about, the museum was average.\n",
        "Sentiment = Neutral\n",
        "\n",
        "4. {test}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LppHuY3v_CaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
        "\n",
        "{instruction_key}\n",
        "{instruction}\n",
        "{response_key}\n",
        "\n",
        "{end_key}\n",
        "\"\"\".format(intro = INTRO_BLURB,\n",
        "           instruction_key = INSTRUCTION_KEY,\n",
        "           instruction = example_string,\n",
        "           response_key = RESPONSE_KEY,\n",
        "           end_key = END_KEY)\n",
        "\n",
        "print(PROMPT_FOR_GENERATION_FORMAT)\n"
      ],
      "metadata": {
        "id": "jRGpmUSa-hcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd0d822f-d5e5-4d97-ec61-3321a7b62a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "You will be given a few example sentences with their correct sentiment. Learn to identify the sentiment of the text and predict whether it is Negative, Positive or Neutral. \n",
            "Only respond with the sentiment label.\n",
            "\n",
            "### EXAMPLES\n",
            "1. This is awesome!\n",
            "Sentiment = Positive\n",
            "\n",
            "2. This is bad! \n",
            "Sentiment = Negative\n",
            "\n",
            "3. Well not much to speak about, the museum was average.\n",
            "Sentiment = Neutral\n",
            "\n",
            "4. That was an awesome class and an even cooler teacher. I liked how she was patient and was good at explaining things. Definitely will take the class again.\n",
            "\n",
            "### Response:\n",
            "Sentiment = \n",
            "\n",
            "### End\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_answer(PROMPT_FOR_GENERATION_FORMAT))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfIlHv4m_0u7",
        "outputId": "4c5ebc6e-287e-443a-c432-0024c8a62e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **b. Negative**"
      ],
      "metadata": {
        "id": "W-skqLUWLSi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = t2\n",
        "\n",
        "example_2 = f\"\"\"\n",
        "You will be given a few example sentences with their correct sentiment. Learn to identify the sentiment of the text and predict whether it is Negative, Positive or Neutral.\n",
        "Only respond with the sentiment label.\n",
        "\n",
        "### EXAMPLES\n",
        "1. This is awesome!\n",
        "Sentiment = Positive\n",
        "\n",
        "2. This is bad!\n",
        "Sentiment = Negative\n",
        "\n",
        "3. Well not much to speak about, the museum was average.\n",
        "Sentiment = Neutral\n",
        "\n",
        "4. {test}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vmfU2iY9LSi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
        "\n",
        "{instruction_key}\n",
        "{instruction}\n",
        "\n",
        "{response_key}\n",
        "\n",
        "{end_key}\n",
        "\"\"\".format(intro = INTRO_BLURB,\n",
        "           instruction_key = INSTRUCTION_KEY,\n",
        "           instruction = example_2,\n",
        "           response_key = RESPONSE_KEY,\n",
        "           end_key = END_KEY)\n",
        "\n",
        "print(PROMPT_FOR_GENERATION_FORMAT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhtr6dKzLSi7",
        "outputId": "20359b60-2c28-4fec-92c5-ff8fc4f11daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "You will be given a few example sentences with their correct sentiment. Learn to identify the sentiment of the text and predict whether it is Negative, Positive or Neutral.\n",
            "Only respond with the sentiment label.\n",
            "\n",
            "### EXAMPLES\n",
            "1. This is awesome!\n",
            "Sentiment = Positive\n",
            "\n",
            "2. This is bad!\n",
            "Sentiment = Negative\n",
            "\n",
            "3. Well not much to speak about, the museum was average.\n",
            "Sentiment = Neutral\n",
            "\n",
            "4. Hmm this was terrible. What a waste of my time!\n",
            "\n",
            "\n",
            "### Response:\n",
            "Sentiment = \n",
            "\n",
            "### End\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_answer(PROMPT_FOR_GENERATION_FORMAT))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c25b5e-8424-444c-ccfd-905d1099509c",
        "id": "5-3J1b8eLSi7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n"
          ]
        }
      ]
    }
  ]
}